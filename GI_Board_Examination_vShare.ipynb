{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammargolis/GI-Board-Examination/blob/main/GI_Board_Examination_vShare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guide for the GI Board Examination Script\n",
        "\n",
        "This guide will assist you in setting up and running the `GI board examination vShare` Python script. The script is designed to automate the uploading, extraction, and analysis of data related to GI Board Examinations. Here's how to get everything set up and running smoothly.\n",
        "\n",
        "#### Requirements\n",
        "Before running the script, ensure that you have the following:\n",
        "- **Python Environment**: A Python environment that supports package installation, such as Anaconda or a virtual environment in a development setup like Jupyter Notebook or Google Colab.\n",
        "- **Internet Connection**: Required for installing packages and potentially for API calls.\n",
        "\n",
        "#### Installation of Dependencies\n",
        "All dependencies are listed within the code blocks.  Packages can often be updated and may require updates\n",
        "\n",
        "#### Files Needed\n",
        "To run the script, you will need the following files:\n",
        "- **`2022_Test_Blank.csv`**: Contains the blank GI board exam questions with text and references to associated images stored in `2022_ACG_Files.zip`. Place this file in a directory that the script can access.\n",
        "- **`ACG_self_assessment_examples.csv`**: Includes 5-shot learning examples with textual content and references to images in `Example_Images.zip`. Place this file in a directory that the script can access.\n",
        "- **`2022_ACG_Files.zip`**: Contains all images referenced in the `2022_Test_Blank.csv`, necessary for the visual components of the exam questions. Ensure this file is in the same directory as the script.\n",
        "- **`Example_Images.zip`**: Holds all images referenced in the `ACG_self_assessment_examples.csv`, providing visual support for the assessment examples. Ensure this file is in the same directory as the script.\n",
        "- **API Key**: You need an API key for OpenAI & Gemini services. Store this securely and update the script to retrieve this key as needed.\n",
        "\n",
        "All files can be found in the Google Drive Link here: https://drive.google.com/drive/folders/116W2snTaJ6l4Y55oDu9mpjF1pdW6gdul?usp=sharing\n",
        "\n",
        "#### Example Image Files\n",
        "If the script processes or generates images, ensure that these image files are correctly formatted and named according to the script's requirements. Include them in the directory or upload feature as needed."
      ],
      "metadata": {
        "id": "n8DpagFVVY5r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9gmnDXrc6YD"
      },
      "source": [
        "## Initial Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGz9q4L6QdE5",
        "outputId": "6e338e8f-fde8-497a-9e8c-7ce24fa9809e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain)\n",
            "  Downloading langchain_core-0.2.7-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.6/315.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.7 langchain-text-splitters-0.2.1 langsmith-0.1.77 orjson-3.10.5\n",
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n",
            "Collecting patool\n",
            "  Downloading patool-2.2.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.2.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.7)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.5 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install patool\n",
        "!pip install requests\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbeyyXeIQfmH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from pathlib import Path\n",
        "import base64\n",
        "import time\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import os, glob\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "import patoolib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "evF1AVICQgYm",
        "outputId": "2be18e45-d882-4008-920b-7c13768d8b30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94d4bb88-021d-4e77-a508-bb21f3b6d47a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-94d4bb88-021d-4e77-a508-bb21f3b6d47a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving GIRedoUpdate.csv to GIRedoUpdate.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RahisI8Qjth"
      },
      "outputs": [],
      "source": [
        "# Dataset is now stored in a Pandas Dataframe\n",
        "testMedicalDF = pd.read_csv(io.BytesIO(uploaded['2022_Test_Blank.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "T4Re3VlDUnLL",
        "outputId": "356e421d-1c59-4103-cb08-175f0da62c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting 2022_ACG_Files.zip ...\n",
            "INFO:patool:Extracting 2022_ACG_Files.zip ...\n",
            "INFO patool: running /usr/bin/7z x -o/content -- 2022_ACG_Files.zip\n",
            "INFO:patool:running /usr/bin/7z x -o/content -- 2022_ACG_Files.zip\n",
            "INFO patool:     with input=''\n",
            "INFO:patool:    with input=''\n",
            "INFO patool: ... 2022_ACG_Files.zip extracted to `/content'.\n",
            "INFO:patool:... 2022_ACG_Files.zip extracted to `/content'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "patoolib.extract_archive(\"2022_ACG_Files.zip\",outdir=\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure you add your API key into the collab secrets\n",
        "openai_api_key= userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "g9O2Mkc7N_UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-e_8oZm8988"
      },
      "outputs": [],
      "source": [
        "image_folder_path=\"/content/2022_ACG_Files/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqHqmTNt4_vQ"
      },
      "outputs": [],
      "source": [
        "base_prompt= \"\"\"\n",
        "Please answer the question\n",
        "\n",
        "Format your response as follows:\n",
        "\n",
        "Multiple choice answer to the question:\n",
        "\n",
        "Justification:\n",
        "\"\"\"\n",
        "sys_prompt= \"\"\"\n",
        "You are an expert in gastroenterology, hepatology, and interventional gastroenterology with extensive experience in endoscopic procedures, radiographic image interpretation (MRI, CT, Ultrasound), and esophageal manometry studies. You have a deep understanding of both normal and abnormal findings in these areas. Additionally, you are well-versed in the medical guidelines from leading organizations such as the ACG, AGA, AASLD, and ASGE, and you're familiar with gastroenterology and hepatology board exam review preparation content.\n",
        "\n",
        "Given a gastroenterology and hepatology board exam question, which may include associated images, apply the following approach:\n",
        "\n",
        "Read the Question: Understand the clinical scenario and what it asks you to identify or solve.\n",
        "Analyze Images (if any): Describe observed findings and relate them to the clinical question.\n",
        "Evaluate Answer Choices: Use your expertise, understanding of guidelines, and test-taking skills to assess each option.\n",
        "Select the Best Answer: Choose the option that best fits the clinical scenario based on evidence and guidelines.\n",
        "Please format your response as below:\n",
        "\n",
        "Multiple Choice Answer: Provide the letter or option you've chosen.\n",
        "Justification: Briefly explain why this answer is the most appropriate, including any relevant clinical guidelines, findings from images, or key points from the question stem that guided your decision\n",
        "\"\"\"\n",
        "reviewer_prompt=\"\"\"\n",
        "Expertise and Role Description: You possess specialized knowledge in gastroenterology and hepatology with skills in endoscopic procedure image interpretation, interpreting radiographic images (MRI, CT, Ultrasound), and manometry. You are very familiar with clinical guidelines from medical societies such as the ACG, AGA, AASLD, and ASGE. Additionally, you have experience with gastroenterology and hepatology board exam preparatory content. Your primary role is to critically assess a response to a practice exam question, incorporating image analysis if images are provided and detailed examination of the provided answers.\n",
        "Review Process:\n",
        "Step 1: Thoroughly review the board exam practice question. Understand the clinical scenario and the specific inquiry posed.\n",
        "Step 2: Examine the provided answer to the question along with the rationale. Consider the details of the question from Step 1.\n",
        "Step 3: Review all the given answer choices with a focus on detail, linking back to your understanding from Steps 1 and 2.\n",
        "Step 4: Based on your comprehensive review from Steps 1-3, determine the accuracy of the selected answer in Step 2. Use your expertise to evaluate the answer. Be detail oriented. Take your time. Be systematic. If the initial answer is correct, confirm it with your endorsement. If incorrect, identify the right answer, providing a thorough justification based on clinical guidelines, radiographic findings, and key aspects of the question.\n",
        "Response Formatting:\n",
        "Multiple Choice Answer: Indicate the best answer (either confirm the existing answer or provide a corrected option based on your reasoning from step 4).\n",
        "Justification: Elaborate on why the answer you chose is the most appropriate. Include references to relevant clinical guidelines, radiographic interpretations, or critical details from the question stem that influenced your decision.\n",
        "Additional Guidelines:\n",
        "Ensure meticulous evaluation, grounding your justification in solid evidence and contemporary medical standards.\n",
        "Consider any provided images as part of the response. If images are pertinent but overlooked in the provided answer, reassess their impact on the question and possibly revise your answer choice.\n",
        "Analyze the logic used in the provided answer for accuracy and consistency with the question, answer choices, and any associated images. Address any incorrect assumptions or errors found in the thought process. If such inaccuracies might influence the correct answer, adjust your response accordingly.\n",
        "Verify that the explanations and justifications in the chosen answer are accurate and align with the information from the question stem and any images provided. If you find inconsistencies or inaccuracies, assess whether these could alter the correct answer choice.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMoNe9s8QBA0"
      },
      "source": [
        "## RAG Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMPsM033QAFe",
        "outputId": "22ba1559-1741-4548-9729-f39233a10782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ],
      "source": [
        "# Package management\n",
        "!pip install langchain --upgrade\n",
        "!pip install pypdf\n",
        "!pip install llama-index\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlW_AD9aQ18E",
        "outputId": "182c7f0a-3788-402f-d872-63a350649107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "#Some packages may not download initially.  If they do not, uninstall and reinstall the package.\n",
        "!pip install openai --upgrade\n",
        "!pip install chromadb --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1fohWZgQ9oc"
      },
      "source": [
        "## RAG Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Didq903lQ5BP"
      },
      "outputs": [],
      "source": [
        "# Additional packages to download.  At times some of the langchain packages can give issues.  If they do I recommend restarting the cluster or going through to download/ upgrade the necessary packages\n",
        "# PDF Loaders. If unstructured gives you a hard time, try PyPDFLoader\n",
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "#load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ofLWG35RCPG"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(file_path=\"/content/combined_text_file.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xew_GiFsRE-b"
      },
      "outputs": [],
      "source": [
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0JKIu2QRJa6",
        "outputId": "b907848c-680e-40ad-e9fd-d8f0f3990509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 1 document(s) in your data\n",
            "There are 26396102 characters in your sample document\n",
            "Here is a sample: PRACTICE GUIDANCE\n",
            "A multidisciplinary approach to the diagnosis and\n",
            "management of Wilson disease: 2022 Practice Guidance onWilson disease from the American Association for the Studyof Liver Diseases\n",
            "M\n"
          ]
        }
      ],
      "source": [
        "# Note: If you switched to using PyPDFLoader then it will split by page for you already\n",
        "print (f'You have {len(data)} document(s) in your data')\n",
        "print (f'There are {len(data[0].page_content)} characters in your sample document')\n",
        "print (f'Here is a sample: {data[0].page_content[:200]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHE3kRt8RMKf"
      },
      "outputs": [],
      "source": [
        "# We'll split our data into chunks around 500 characters each with a 50 character overlap. These are relatively small.  We use this so that we can pass multiple small relevant chunks of documentation\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax8d2tdbROSV",
        "outputId": "84b2b0eb-0cf9-497c-9fad-c187cfc6bb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 61350 documents\n"
          ]
        }
      ],
      "source": [
        "# Sense check on number of documents\n",
        "print (f'Now you have {len(texts)} documents')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOpdDJFORRGt"
      },
      "outputs": [],
      "source": [
        "openai_api_key= userdata.get('openai_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYy-PqFQRSu8",
        "outputId": "2f494d09-daad-4775-f07b-0c091e91f064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4iYuo9RRWG9"
      },
      "outputs": [],
      "source": [
        "# load it into Chroma\n",
        "vectorstore = Chroma.from_documents(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHmX-sf7RWq5"
      },
      "outputs": [],
      "source": [
        "query = \"What should I do for GERD?\"\n",
        "docs = vectorstore.similarity_search(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are a few checks to make sure the RAG is working correctly"
      ],
      "metadata": {
        "id": "1Y1FUkrvQNvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZutSQ8-RYW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd10f2e3-788a-454b-b998-2473c2a19400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For patients presenting with GERD symptoms, a\n",
            "stepwise diagnostic approach will identify mechanismsdriving symptoms for a precision managementapproach. Patients should receive education on GERDpathophysiology and lifestyle modi cations, and be\n",
            "involved in a shared decision-making model. A 4- to 8-\n",
            "week trial of single-dose PPI is considered safe and\n",
            "appropriate for patients with typical re ux symptoms\n",
            "\n",
            "We suggest elevating head of bed for nighttime GERD symptoms. Low ConditionalWe recommend treatment with PPIs over treatment with H2RA for healing EE. High StrongWe recommend treatment with PPIs over H2RA for maintenance of healing for EE. Moderate StrongWe recommend PPI administration 30 60 min before a meal rather than at bedtime for GERD symptom\n",
            "control.Moderate Strong\n",
            "For patients with GERD who do not have EE or Barrett s esophagus, and whose symptoms have resolved\n",
            "\n",
            "meal rather than at bedtime for GERD symptom control (strongrecommendation, moderate level of evidence).\n",
            "9. For patients with GERD who do not have EE or Barrett s\n",
            "esophagus, and whose symptoms have resolved with PPItherapy, an attempt should be made to discontinue PPIs or toswitch to on-demand therapy in which PPIs are taken only when\n",
            "symptoms occur and discontinued when they are relieved\n",
            "(conditional recommendation, low level of evidence).\n",
            "\n",
            "2. We recommend that patients who have extraesophageal\n",
            "manifestations of GERD without typical GERD symptoms (e.g.,\n",
            "heartburn and regurgitation) undergo reflux testing for evaluationbefore PPI therapy (strong recommendation, moderate level ofevidence).\n",
            "3. For patients who have both extraesophageal and typical GERD\n",
            "symptoms, we suggest considering a trial of twice-daily PPItherapy for 8 12 weeks before additional testing (conditional\n",
            "recommendation, low level of evidence).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Here's an example of the first document that was returned\n",
        "for doc in docs:\n",
        "    print (f\"{doc.page_content}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68a4nHyxMyZ5"
      },
      "outputs": [],
      "source": [
        "testQ = \"\"\"\n",
        "A 37-year-old man with human immunodeficiency virus and a history of Pneumocystis jirovecii pneumonia, presented to the hospital with diarrhea and hypotension. Over the past month, he reports increasingly watery diarrhea, upwards of 8-10 times per day, with nocturnal symptoms and episodes of fecal incontinence. He also reports diffuse abdominal pain and cramping, night sweats, lethargy, and new cough. He has no headache, arthralgias, or rashes. He reports that he has not been compliant with his anti-retroviral therapy for the past year.\n",
        "\n",
        "On arrival to the hospital, his vital signs are notable for a temperature of 102.7°F, heart rate of 107 beats per minute, and blood pressure 92/61 mm Hg. On examination, he is pale, diaphoretic, but oriented to person, place, and time. His cardiac examination is notable for tachycardia with a soft systolic murmur. His pulmonary examination reveals diffuse rhonchi in the upper lobes bilaterally. His abdomen is soft, but diffusely tender. Laboratory studies in the ED are notable for sodium 124 mEq/L (normal: 136-145 mEq/L), potassium 2.7 mEq/L (normal: 3.5-5.0 mEq/L), white blood cell count 4,500/µL (normal: 4,000-10,000/µL), albumin 1.9 g/dL (normal: 3.5-5.5 g/dL), AST and ALT were normal, but his CD4 count was 9/µL. Chest radiograph showed upper lobe infiltrates bilaterally. An upper endoscopy and colonoscopy are performed for evaluation of diarrhea with the finding in the duodenum shown in the figure. The pathology from the duodenal biopsies demonstrated numerous foamy macrophages filling the lamina propria with intracellular periodic acid-Schiff (PAS)-positive organisms. What is the most likely etiology of the patient’s symptoms?\n",
        "\n",
        "\n",
        "A\n",
        "Mycobacterium avium intracellulare complex\n",
        "\n",
        "B\n",
        "Cryptosporidium parvum\n",
        "\n",
        "C\n",
        "Tropheryma whipplei\n",
        "\n",
        "D\n",
        "Histoplasma capsulatum\n",
        "\"\"\"\n",
        "docs = vectorstore.similarity_search(testQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1b1a-pcNMbh",
        "outputId": "8947953f-6e38-4824-82b2-f28d91c29a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a study of more than 15,000 hospitalized HIV patients in1998, 2.8% were admitted for a diarrheal diagnosis.\n",
            "66Data\n",
            "on the endoscopic evaluation of patients with HIV are\n",
            "mostly from studies that preceded the use of highly active\n",
            "antiretroviral therapy.67Although CMV is the most common\n",
            "pathogen detected in these patients, histopathologic evalu-ation may identify other pathogens, such as adenovirus andenteropathogenic bacteria.\n",
            "68-70Furthermore, a pathogen\n",
            "\n",
            "Pathol 1996;106:544-8.\n",
            "66. Anastasi JK, Capili B. HIV and diarrhea in the era of HAART: 1998 New\n",
            "York State hospitalizations. Am J Infect Control 2000;28:262-6.\n",
            "67. Orenstein JM, Dieterich DT. The histopathology of 103 consecutive co-\n",
            "lonoscopy biopsies from 82 symptomatic patients with acquired im-\n",
            "munodeficiency syndrome. Arch Pathol Lab Med 2001;125:1042-6.\n",
            "68. Bini EJ. Endoscopic approach to HIV associated diarrhea: how far is far\n",
            "enough? Am J Gastroenterol 1999;94:556-9.\n",
            "\n",
            "74. Mo nkemu ller KE, Wilcox CM. Investigation of diarrhea in AIDS. Can J\n",
            "Gastroenterol 2000;14:933-40.\n",
            "75. Wilcox CM. Role of endoscopy in the investigation of upper gastrointestinal\n",
            "symptoms in HIV-infected patients. Can J Gastroenterol 1999;13:305-10.\n",
            "76. Bini EJ, Weinshel EH, Gamagaris Z. Comparison of duodenal with jeju-\n",
            "nal biopsy and aspirate in chronic human immunodeficiency virus-\n",
            "related diarrhea. Am J Gastroenterol 1998;93:1837-40.\n",
            "\n",
            "enough? Am J Gastroenterol 1999;94:556-9.\n",
            "69. Bini EJ, Weinshel EH. Endoscopic evaluation of chronic human immu-\n",
            "nodeficiency virus-related diarrhea: is colonoscopy superior to flexiblesigmoidoscopy? Am J Gastroenterol 1998;93:56-60.\n",
            "70. Wilcox CM, Schwartz DA, Cotsonis G, et al. Chronic unexplained diar-\n",
            "rhea in human immunodeficiency virus infection: determination of thebest diagnostic approach. Gastroenterology 1996;110:30-7.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Here's an example of the first document that was returned\n",
        "for doc in docs:\n",
        "    print (f\"{doc.page_content}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5sWHZYbOTr3"
      },
      "outputs": [],
      "source": [
        "docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YksEK-YQW4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "fd1038b4-8c78-487f-88a5-51ff8b1260aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In a study of more than 15,000 hospitalized HIV patients in1998, 2.8% were admitted for a diarrheal diagnosis.\\n66Data\\non the endoscopic evaluation of patients with HIV are\\nmostly from studies that preceded the use of highly active\\nantiretroviral therapy.67Although CMV is the most common\\npathogen detected in these patients, histopathologic evalu-ation may identify other pathogens, such as adenovirus andenteropathogenic bacteria.\\n68-70Furthermore, a pathogen\\n\\nPathol 1996;106:544-8.\\n66. Anastasi JK, Capili B. HIV and diarrhea in the era of HAART: 1998 New\\nYork State hospitalizations. Am J Infect Control 2000;28:262-6.\\n67. Orenstein JM, Dieterich DT. The histopathology of 103 consecutive co-\\nlonoscopy biopsies from 82 symptomatic patients with acquired im-\\nmunodeficiency syndrome. Arch Pathol Lab Med 2001;125:1042-6.\\n68. Bini EJ. Endoscopic approach to HIV associated diarrhea: how far is far\\nenough? Am J Gastroenterol 1999;94:556-9.\\n\\n74. Mo nkemu ller KE, Wilcox CM. Investigation of diarrhea in AIDS. Can J\\nGastroenterol 2000;14:933-40.\\n75. Wilcox CM. Role of endoscopy in the investigation of upper gastrointestinal\\nsymptoms in HIV-infected patients. Can J Gastroenterol 1999;13:305-10.\\n76. Bini EJ, Weinshel EH, Gamagaris Z. Comparison of duodenal with jeju-\\nnal biopsy and aspirate in chronic human immunodeficiency virus-\\nrelated diarrhea. Am J Gastroenterol 1998;93:1837-40.\\n\\nenough? Am J Gastroenterol 1999;94:556-9.\\n69. Bini EJ, Weinshel EH. Endoscopic evaluation of chronic human immu-\\nnodeficiency virus-related diarrhea: is colonoscopy superior to flexiblesigmoidoscopy? Am J Gastroenterol 1998;93:56-60.\\n70. Wilcox CM, Schwartz DA, Cotsonis G, et al. Chronic unexplained diar-\\nrhea in human immunodeficiency virus infection: determination of thebest diagnostic approach. Gastroenterology 1996;110:30-7.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "docs_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ylXu9SvYRsXy",
        "outputId": "667210dd-4d12-4b4e-d48c-556acc30d25a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In a study of more than 15,000 hospitalized HIV pa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "docs_content[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEJ2eqZ30gOf"
      },
      "source": [
        "## OpenAI Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8Yvrv1W6PP5"
      },
      "outputs": [],
      "source": [
        "# Searches for files in the specified folder path that match the given filename without an extension,\n",
        "# appending any extension available. Returns the first match found with its complete filename and extension.\n",
        "# Parameters:\n",
        "# folder_path (str): The directory path where the file will be searched.\n",
        "# filename_without_extension (str): The base name of the file without any extension.\n",
        "# Returns:\n",
        "# str: The complete filename with extension of the first matching file, or None if no match is found.\n",
        "def find_file_extension(folder_path, filename_without_extension):\n",
        "    # Create a search pattern\n",
        "    search_pattern = os.path.join(folder_path, filename_without_extension + \".*\")\n",
        "\n",
        "    # Use glob to find matching files\n",
        "    matching_files = glob.glob(search_pattern)\n",
        "\n",
        "    if not matching_files:\n",
        "        return None  # No matching file found\n",
        "\n",
        "    # Assuming you want the first matching file\n",
        "    first_matching_file = matching_files[0]\n",
        "\n",
        "    # Extract the complete file name\n",
        "    complete_file_name = os.path.basename(first_matching_file)\n",
        "\n",
        "    return complete_file_name\n",
        "\n",
        "\n",
        "# Retrieves documents similar to the provided question using a vector store's similarity search, concatenating the page contents of each resulting document into a single string.\n",
        "# Parameters:\n",
        "# question (str): The query question for retrieving relevant documents.\n",
        "# Returns:\n",
        "# str: Concatenated page contents of all documents similar to the question.\n",
        "def getRagDocs(question):\n",
        "  docs = vectorstore.similarity_search(question)\n",
        "  docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "  return docs_content\n",
        "\n",
        "\n",
        "# Encodes an image from the given path to a base64 string, allowing for image data to be easily transmitted or stored in text format.\n",
        "# Parameters:\n",
        "# image_path (str): The file path of the image to encode.\n",
        "# Returns:\n",
        "# str: The base64-encoded representation of the image.\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "\n",
        "# Encodes multiple images from a list of filenames within a specified folder into their base64 string representations.\n",
        "# Parameters:\n",
        "# file_list (list): A list of filenames to be converted.\n",
        "# folder_path (str): The path to the folder containing the images.\n",
        "# Returns:\n",
        "# list: A list of base64-encoded strings of the images.\n",
        "def Build64(file_list, folder_path):\n",
        "    base64_images = []\n",
        "    # print(file_list)\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.exists(file_path):\n",
        "          # print(encode_image(file_path))\n",
        "          base64_images.append(encode_image(file_path))\n",
        "    return base64_images\n",
        "\n",
        "# Sends a JSON payload to the OpenAI API and handles the response, retrying upon failures and handling errors.\n",
        "# Parameters:\n",
        "# payload (dict): The JSON payload to be sent to the API.\n",
        "# Returns:\n",
        "# dict: The JSON response from the API or an error message with status code.\n",
        "def ChatRequest(payload):\n",
        "    api_key = openai_api_key\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    while True:\n",
        "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "        print(f\"Request Status Code: {response.status_code}\")\n",
        "        if response.status_code == 400:\n",
        "            # If the status code is 400, print the error and break the loop\n",
        "            print(\"Bad request. Please check your payload for errors.\")\n",
        "            break  # Break the loop on a 400 status code\n",
        "        elif response.status_code != 200:\n",
        "            # Assume rate is limited or other errors and wait 25 seconds.\n",
        "            default_wait = 25\n",
        "            print(f\"Failed request, status code: {response.status_code}, waiting {default_wait} seconds.\")\n",
        "            time.sleep(default_wait)\n",
        "        else:\n",
        "            # If the request is successful, break the loop and return the response\n",
        "            break\n",
        "    if response.status_code == 400:\n",
        "        return {\"error\": \"Bad request\", \"status_code\": 400}  # Return an error message and status code\n",
        "    else:\n",
        "        return response  # Return the successful response\n",
        "\n",
        "\n",
        "\n",
        "# Prepares a JSON payload including system and user prompts, images, and the main question for interaction via OpenAI's API. It sends this payload through the ChatRequest function and processes the response.\n",
        "# Parameters:\n",
        "# sys_prompt (str): System-generated introductory text.\n",
        "# user_prompt (str): User-provided context or prompt.\n",
        "# initialAnswer (str): Initial automated response.\n",
        "# question (str): Main question to be addressed in the interaction.\n",
        "# model (str): Identifier for the AI model to use.\n",
        "# batch (list): List of base64-encoded images to include in the payload.\n",
        "# Returns:\n",
        "# dict: A dictionary containing the API's response and tokens used for the completion.\n",
        "def vchatreviewer(sys_prompt, user_prompt, initialAnswer, question, model, batch):\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": sys_prompt}]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": []  # Initial empty content, will populate below\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Question for the model, given after the examples if any\n",
        "    question_message = {\n",
        "        \"type\": \"text\",\n",
        "        \"text\": f\"\\n Here is the question you will answer:\\n{question}\\n\\n\\n\"\n",
        "    }\n",
        "    messages[1][\"content\"].append(question_message)\n",
        "\n",
        "\n",
        "    # Add image_url messages for each base64 encoded image in the batch\n",
        "    for base64_image in batch:\n",
        "        image_message = {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "        }\n",
        "        messages[1][\"content\"].append(image_message)\n",
        "\n",
        "    # Construct the JSON payload\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": 4096  # Modify as needed, 4096 can get expensive with little value\n",
        "    }\n",
        "\n",
        "    # Assume ChatRequest is a function that sends the payload to the API\n",
        "    response = ChatRequest(payload)\n",
        "    # Curate the response object\n",
        "    response_data = response.json()\n",
        "    assistant_response = response_data['choices'][0]['message']['content']\n",
        "    completion_tokens_used = response_data['usage']['completion_tokens']\n",
        "\n",
        "    res_dict = {\"response\": assistant_response, \"tokens\": completion_tokens_used}\n",
        "    return res_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are including 5-shot examples use the 2 cells below.  Find the necessary files for the examples here:"
      ],
      "metadata": {
        "id": "msJCx6DJAA0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exampleShots = pd.read_csv(io.BytesIO(uploaded['ACG_self_assessment_examples.csv']))\n",
        "patoolib.extract_archive(\"Example_Images.zip\",outdir=\"/content\")\n",
        "bool_example=True\n",
        "example_image_folder_path=\"/content/Example_Images\""
      ],
      "metadata": {
        "id": "FzcAsG4wQ_Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMaPL84h5SeR",
        "outputId": "a2402f8e-b531-485c-d91b-8f112d04fc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023C4\n",
            "2023P2\n",
            "2023C5\n",
            "2023st15\n",
            "2023l9\n"
          ]
        }
      ],
      "source": [
        "example_list = []\n",
        "#If the user has opted-in to the example check box, create the example_list from the excel sheet.\n",
        "if bool_example:\n",
        "  for index, row in exampleShots.iterrows():\n",
        "    if pd.notnull(row['question']):\n",
        "      question_num = row[0]\n",
        "      print(question_num)\n",
        "      #Initiallize lists to hold image file names and the base64 images\n",
        "      batch_file_names = []\n",
        "      batch = []\n",
        "\n",
        "      if not any(row):  # Check if the entire row is empty\n",
        "        break  # Stop reading when an empty row is encountered\n",
        "      first_7_cells = row[:7]  # Get the first 7 cells of the row\n",
        "      # Loop through the last 5 cells in first_5_cells and check if they are empty\n",
        "      for cell_value in first_7_cells[-5:]:\n",
        "          if cell_value is None or cell_value == \"\" or pd.isna(cell_value):\n",
        "              break  # Exit the inner loop if an empty cell is found\n",
        "          else:\n",
        "              image_file_name=cell_value\n",
        "              #Use the code below if the file extension is not provided\n",
        "              image_file_name = find_file_extension(example_image_folder_path, cell_value)\n",
        "              batch_file_names.append(str(image_file_name))\n",
        "\n",
        "      batch = Build64(batch_file_names, example_image_folder_path)\n",
        "\n",
        "      #Extract question from excel sheet\n",
        "      question = row['question']\n",
        "      answer = row['Sample answer']\n",
        "      example_list.append([question, batch, answer])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each row and fill in the answers.\n",
        "# This is not the most elegant approach but with a small n (300) it works well\n",
        "\n",
        "for index, row in testMedicalDF.iterrows():\n",
        "    if pd.notnull(row['Question']):\n",
        "      question_num = row[0]\n",
        "      print(question_num)\n",
        "      #Initiallize lists to hold image file names and the base64 images\n",
        "      batch_file_names = []\n",
        "      batch = []\n",
        "\n",
        "      if not any(row):  # Check if the entire row is empty\n",
        "          break  # Stop reading when an empty row is encountered\n",
        "      first_7_cells = row[:7]  # Get the first 7 cells of the row\n",
        "      # Loop through the last 5 cells in first_5_cells and check if they are empty\n",
        "      for cell_value in first_7_cells[-5:]:\n",
        "          if cell_value is None or cell_value == \"\" or pd.isna(cell_value):\n",
        "              break  # Exit the inner loop if an empty cell is found\n",
        "          else:\n",
        "              image_file_name=cell_value\n",
        "              #Use the code below if the file extension is not provided\n",
        "              # image_file_name = find_file_extension(image_folder_path, cell_value)\n",
        "              batch_file_names.append(str(image_file_name))\n",
        "\n",
        "      print(batch_file_names)\n",
        "\n",
        "      batch = Build64(batch_file_names, image_folder_path)\n",
        "\n",
        "      #Extract question from excel sheet\n",
        "      question = row['Question']\n",
        "\n",
        "      # intialAnswer = row['Initial Answer']\n",
        "      intialAnswer = \"none\"\n",
        "\n",
        "      #Call the API to answer the question using vision or no vision\n",
        "      results = vchatreviewer(reviewer_prompt, user_prompt, intialAnswer, question, \"gpt-4-turbo\", batch)\n",
        "\n",
        "      if 'error' in results and results['status_code'] == 400:\n",
        "        print(\"Encountered a bad request error. Stopping further processing for this row.\")\n",
        "        results= \"Error encountered\"\n",
        "        continue  # Skip the rest of the current iteration and move to the next row\n",
        "\n",
        "      answer = str(results[\"response\"])  # Extracts the answer from results if no error\n",
        "      testMedicalDF.at[index, 'Correct answer'] = answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58_Q7L3qAdqp",
        "outputId": "0c795344-a863-4116-a901-8f97f47cb9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3sb\n",
            "['3sb1.jpg', '3sb2.jpg', '3sb3.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n",
            "3sb\n",
            "['3sb1.jpg', '3sb2.jpg', '3sb3.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n",
            "3sb\n",
            "['3sb1.jpg', '3sb2.jpg', '3sb3.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n",
            "3sb\n",
            "['3sb1.jpg', '3sb2.jpg', '3sb3.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n",
            "3sb\n",
            "['3sb1.jpg', '3sb2.jpg', '3sb3.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n",
            "3sb\n",
            "['3sb1.jpg', '3sb2.jpg', '3sb3.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n",
            "5m\n",
            "['5m1.jpg', '5m2.jpg']\n",
            "Request Status Code: 200\n",
            "1IBD\n",
            "['1IBD1.jpg']\n",
            "Request Status Code: 200\n",
            "7es\n",
            "['6es1.png']\n",
            "Request Status Code: 200\n",
            "10st\n",
            "[]\n",
            "Request Status Code: 200\n",
            "11m\n",
            "['11m1.png']\n",
            "Request Status Code: 200\n",
            "17IBD\n",
            "['16IBD1.jpg', '16IBD2.png']\n",
            "Request Status Code: 200\n",
            "29c\n",
            "['29c1.jpg', '29c2.jpg']\n",
            "Request Status Code: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testMedicalDF.to_csv('20240508ModelRun.csv', index=False)\n",
        "files.download('20240508ModelRun.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T82AFqLGERlf",
        "outputId": "ec758240-322a-45f5-c50d-3a66afa9c5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3619cc1b-ceee-40d3-a9dc-504f4d29e1c4\", \"OpenAI_Incorrects.csv\", 245365)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rONdvI-bc_cK"
      },
      "source": [
        "## Google Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNlIYjKNuvap"
      },
      "source": [
        "###Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjsqGDbadDTl"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install langchain\n",
        "!pip install patool\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahcloJcddLer"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from pathlib import Path\n",
        "import base64\n",
        "import time\n",
        "from google.colab import files\n",
        "import patoolib\n",
        "import PIL.Image\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "237H3rEKdUGx"
      },
      "outputs": [],
      "source": [
        "image_folder_path=\"/content/2022_ACG_Files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s__beI9XdY04"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4ulpNaldcLV"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "JlXKFhmTdelp",
        "outputId": "5a57259a-46ef-4500-a682-82de02e29abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRtZqs-ZdgLT"
      },
      "outputs": [],
      "source": [
        "# Model names change regularly with gemini\n",
        "model = genai.GenerativeModel('gemini-pro-vision')\n",
        "textmodel = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5FF1ha3u1Kg"
      },
      "source": [
        "### Running the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnyQWz4Bdlg3"
      },
      "outputs": [],
      "source": [
        "###\n",
        "# Searches for files in the specified folder path that match the given filename without an extension, appending any extension available. Returns the first match found with its complete filename and extension.\n",
        "# Parameters:\n",
        "# folder *path* (str): The directory path where the file will be searched.\n",
        "# filename *without_extension* (str): The base name of the file without any extension.\n",
        "# Returns:\n",
        "# str: The complete filename with extension of the first matching file, or None if no match is found.\n",
        "###\n",
        "def find_file_extension(folder_path, filename_without_extension):\n",
        "    # Create a search pattern\n",
        "    search_pattern = os.path.join(folder_path, filename_without_extension + \".*\")\n",
        "\n",
        "    # Use glob to find matching files\n",
        "    matching_files = glob.glob(search_pattern)\n",
        "\n",
        "    if not matching_files:\n",
        "        return None  # No matching file found\n",
        "\n",
        "    # Assuming you want the first matching file\n",
        "    first_matching_file = matching_files[0]\n",
        "\n",
        "    # Extract the complete file name\n",
        "    complete_file_name = os.path.basename(first_matching_file)\n",
        "\n",
        "    return complete_file_name\n",
        "\n",
        "###\n",
        "# Creates a list of PIL image objects from a list of filenames within a specified folder. Each image is opened and added to the list as a PIL image object.\n",
        "# Parameters:\n",
        "# file_list (list): A list of filenames to be opened as images.\n",
        "# folder_path (str): The path to the folder containing the image files.\n",
        "# Returns:\n",
        "# list: A list of PIL Image objects. Each object in the list represents an image file that was opened from the specified folder.\n",
        "###\n",
        "def BuildImageListGoogle(file_list, folder_path):\n",
        "    pil_images = []\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        pil_images.append(PIL.Image.open(file_path))\n",
        "    return pil_images\n",
        "\n",
        "###\n",
        "# Retrieves documents similar to the provided question using a vector store's similarity search, concatenating the page contents of each resulting document into a single string.\n",
        "# Parameters:\n",
        "# question (str): The query question for retrieving relevant documents.\n",
        "# Returns:\n",
        "# str: Concatenated page contents of all documents similar to the question.\n",
        "###\n",
        "def getRagDocs(question):\n",
        "  docs = vectorstore.similarity_search(question)\n",
        "  docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "  return docs_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rVDv6nl8dvoB",
        "outputId": "15771d2f-397a-4b6e-9ab7-43466ccaca51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3sb\n",
            "3sb1.jpg\n",
            "complete\n",
            "3sb2.jpg\n",
            "complete\n",
            "3sb3.jpg\n",
            "complete\n",
            "5m\n",
            "5m1.jpg\n",
            "complete\n",
            "5m2.jpg\n",
            "complete\n",
            "1IBD\n",
            "1IBD1.jpg\n",
            "complete\n",
            "using text model\n",
            "7es\n",
            "6es1.png\n",
            "complete\n",
            "10st\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-pro-vision:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 280.71ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using text model\n",
            "11m\n",
            "11m1.png\n",
            "complete\n",
            "17IBD\n",
            "16IBD1.jpg\n",
            "complete\n",
            "16IBD2.png\n",
            "complete\n",
            "29c\n",
            "29c1.jpg\n",
            "complete\n",
            "29c2.jpg\n",
            "complete\n",
            "3sb\n",
            "3sb1.jpg\n",
            "complete\n",
            "3sb2.jpg\n",
            "complete\n",
            "3sb3.jpg\n",
            "complete\n",
            "5m\n",
            "5m1.jpg\n",
            "complete\n",
            "5m2.jpg\n",
            "complete\n",
            "1IBD\n",
            "1IBD1.jpg\n",
            "complete\n",
            "using text model\n",
            "7es\n",
            "6es1.png\n",
            "complete\n",
            "10st\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-pro-vision:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 381.25ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using text model\n",
            "11m\n",
            "11m1.png\n",
            "complete\n",
            "17IBD\n",
            "16IBD1.jpg\n",
            "complete\n",
            "16IBD2.png\n",
            "complete\n",
            "29c\n",
            "29c1.jpg\n",
            "complete\n",
            "29c2.jpg\n",
            "complete\n",
            "3sb\n",
            "3sb1.jpg\n",
            "complete\n",
            "3sb2.jpg\n",
            "complete\n",
            "3sb3.jpg\n",
            "complete\n",
            "5m\n",
            "5m1.jpg\n",
            "complete\n",
            "5m2.jpg\n",
            "complete\n",
            "1IBD\n",
            "1IBD1.jpg\n",
            "complete\n"
          ]
        }
      ],
      "source": [
        "# Loop through each row and fill in the answers\n",
        "for index, row in testMedicalDF.iterrows():\n",
        "    if pd.notnull(row['Question']):\n",
        "      question_num = row[0]\n",
        "      print(question_num)\n",
        "      #Initiallize lists to hold image file names and the base64 images\n",
        "      batch_file_names = []\n",
        "      batch = []\n",
        "\n",
        "      #Extract question from excel sheet\n",
        "      question = row['Question']\n",
        "\n",
        "      contents = [\n",
        "          sys_prompt\n",
        "      ]\n",
        "      # If it fails on the image model\n",
        "      text_contents = [\n",
        "          sys_prompt\n",
        "      ]\n",
        "\n",
        "      ragDocs=getRagDocs(question)\n",
        "      contents.append(\"\\n\\nBelow is some additional documentation that may or may not be useful.  Try to use the guidelines if you can but do not forget the question asked. \\n\\n\")\n",
        "      contents.append(ragDocs)\n",
        "\n",
        "      text_contents.append(\"\\n\\nBelow is some additional documentation that may or may not be useful.  Try to use the guidelines if you can but do not forget the question asked. \\n\\n\")\n",
        "      text_contents.append(ragDocs)\n",
        "\n",
        "\n",
        "      if not any(row):  # Check if the entire row is empty\n",
        "          break  # Stop reading when an empty row is encountered\n",
        "      first_7_cells = row[:7]  # Get the first 7 cells of the row\n",
        "      # Loop through the last 5 cells in first_5_cells and check if they are empty\n",
        "      for cell_value in first_7_cells[-5:]:\n",
        "          if cell_value is None or cell_value == \"\" or pd.isna(cell_value):\n",
        "              break  # Exit the inner loop if an empty cell is found\n",
        "          else:\n",
        "              # image_file_name = find_file_extension(image_folder_path, cell_value)\n",
        "              image_file_name=cell_value\n",
        "              print(image_file_name)\n",
        "              if image_file_name is not None:\n",
        "                if os.path.exists(image_folder_path):\n",
        "                  file_path = os.path.join(image_folder_path, image_file_name)\n",
        "                  contents.append(PIL.Image.open(file_path))\n",
        "                  print(\"complete\")\n",
        "\n",
        "      contents.append(\"\\n\\nAnd now here is the question that you will be answering.  Please answer this question based on your knowledge and expertise \\n\\n\")\n",
        "      contents.append(question)\n",
        "\n",
        "      text_contents.append(\"\\n\\nAnd now here is the question that you will be answering.  Please answer this question based on your knowledge and expertise \\n\\n\")\n",
        "      text_contents.append(question)\n",
        "\n",
        "\n",
        "      # At times the Gemini model can error out especially the image model.  Use this try catch and include as error if it fails both\n",
        "      try:\n",
        "        results = model.generate_content(contents)\n",
        "        answer = results.text  #extracts the answer from results\n",
        "      except:\n",
        "          try:\n",
        "            results=textmodel.generate_content(text_contents)\n",
        "            answer = results.text  #extracts the answer from results\n",
        "            print(\"using text model\")\n",
        "          except:\n",
        "            answer=\"Error based on input\"\n",
        "            print(\"waiting 10 seconds\")\n",
        "            time.sleep(10)\n",
        "            print(\"Error Caught\")\n",
        "            pass\n",
        "          pass\n",
        "\n",
        "      testMedicalDF.at[index, 'Correct answer'] = answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co2u213mg1Ao"
      },
      "outputs": [],
      "source": [
        "testMedicalDF.to_csv('20240506GeminiModelRun.csv', index=False)\n",
        "files.download('20240506GeminiModelRun.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sMoNe9s8QBA0",
        "k1fohWZgQ9oc",
        "msJCx6DJAA0S",
        "IMjeAA1EBoiN",
        "rONdvI-bc_cK",
        "b5FF1ha3u1Kg",
        "arjxZlarN7Fp",
        "jL6hQ8DncjXG"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMVp5kItkvTyCleATqr3fB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}